{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33639174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,RepeatedStratifiedKFold,cross_val_score\n",
    "from numpy import mean,std\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5117fd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>voice_mail_messages</th>\n",
       "      <th>day_mins</th>\n",
       "      <th>evening_mins</th>\n",
       "      <th>night_mins</th>\n",
       "      <th>international_mins</th>\n",
       "      <th>customer_service_calls</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>day_calls</th>\n",
       "      <th>day_charge</th>\n",
       "      <th>evening_calls</th>\n",
       "      <th>evening_charge</th>\n",
       "      <th>night_calls</th>\n",
       "      <th>night_charge</th>\n",
       "      <th>international_calls</th>\n",
       "      <th>international_charge</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>197.4</td>\n",
       "      <td>244.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>75.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>195.5</td>\n",
       "      <td>254.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>59.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>121.2</td>\n",
       "      <td>162.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>62.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>61.9</td>\n",
       "      <td>196.9</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>66.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>148.3</td>\n",
       "      <td>186.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>52.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  voice_mail_plan  voice_mail_messages  day_mins  \\\n",
       "0             128                1                   25     265.1   \n",
       "1             107                1                   26     161.6   \n",
       "2             137                0                    0     243.4   \n",
       "3              84                0                    0     299.4   \n",
       "4              75                0                    0     166.7   \n",
       "\n",
       "   evening_mins  night_mins  international_mins  customer_service_calls  \\\n",
       "0         197.4       244.7                10.0                       1   \n",
       "1         195.5       254.4                13.7                       1   \n",
       "2         121.2       162.6                12.2                       0   \n",
       "3          61.9       196.9                 6.6                       2   \n",
       "4         148.3       186.9                10.1                       3   \n",
       "\n",
       "   international_plan  day_calls  day_charge  evening_calls  evening_charge  \\\n",
       "0                   0        110       45.07             99           16.78   \n",
       "1                   0        123       27.47            103           16.62   \n",
       "2                   0        114       41.38            110           10.30   \n",
       "3                   1         71       50.90             88            5.26   \n",
       "4                   1        113       28.34            122           12.61   \n",
       "\n",
       "   night_calls  night_charge  international_calls  international_charge  \\\n",
       "0           91         11.01                    3                  2.70   \n",
       "1          103         11.45                    3                  3.70   \n",
       "2          104          7.32                    5                  3.29   \n",
       "3           89          8.86                    7                  1.78   \n",
       "4          121          8.41                    3                  2.73   \n",
       "\n",
       "   total_charge  churn  \n",
       "0         75.56      0  \n",
       "1         59.24      0  \n",
       "2         62.29      0  \n",
       "3         66.80      0  \n",
       "4         52.09      0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/oversampled_data.csv')\n",
    "del data['Unnamed: 0']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321be1d",
   "metadata": {},
   "source": [
    "### Scaling an dseperating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54098f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5700, 18), (5700, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scr = StandardScaler()\n",
    "X = data.drop(labels='churn',axis=1)\n",
    "cols = X.columns\n",
    "X = pd.DataFrame(std_scr.fit_transform(X))\n",
    "X.columns = cols\n",
    "y = data[['churn']]\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4ddef",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f870bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=True,random_state=12,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d3597",
   "metadata": {},
   "source": [
    "### Dict to store performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "533d57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'model':[],'train accuracy':[], 'test accuracy': [],'precision':[],'recall':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc034f75",
   "metadata": {},
   "source": [
    "### Method to predit and calculate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe11755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_matrix(fittedModel):\n",
    "    y_pred_train = fittedModel.predict(x_train)\n",
    "    train_accuracy = round(accuracy_score(y_train,y_pred_train)*100,2)\n",
    "    \n",
    "    y_pred = fittedModel.predict(x_test)\n",
    "    test_accuracy = round(accuracy_score(y_test,y_pred)*100,2)\n",
    "    precision = round(precision_score(y_test,y_pred)*100,2)\n",
    "    recall = round(recall_score(y_test,y_pred)*100,2)\n",
    "    model = str(fittedModel)\n",
    "    my_dict[\"model\"].append(model)\n",
    "    my_dict[\"train accuracy\"].append(train_accuracy)\n",
    "    my_dict[\"test accuracy\"].append(test_accuracy)\n",
    "    my_dict[\"precision\"].append(precision)\n",
    "    my_dict[\"recall\"].append(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ffca8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(model):\n",
    "    # evaluate model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    n_scores = cross_val_score(estimator=model,X=X,y=y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    # report performance\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350d0ca",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10c5c4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "cross_validate_model(logistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b6a67",
   "metadata": {},
   "source": [
    "### Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7dd41f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()'], 'train accuracy': [78.31], 'test accuracy': [76.75], 'precision': [75.63], 'recall': [78.95]}\n"
     ]
    }
   ],
   "source": [
    "logistic.fit(x_train,y_train)\n",
    "populate_matrix(logistic)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f70f5",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c340f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.983 (0.005)\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "# evaluate model\n",
    "cross_validate_model(dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc4fe3",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5da236e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()'], 'train accuracy': [78.31, 100.0], 'test accuracy': [76.75, 98.25], 'precision': [75.63, 96.77], 'recall': [78.95, 99.82]}\n"
     ]
    }
   ],
   "source": [
    "dtree.fit(x_train,y_train)\n",
    "populate_matrix(dtree)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afc17c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45529565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999 (0.001)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# evaluate model\n",
    "cross_validate_model(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88c177",
   "metadata": {},
   "source": [
    "### Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77af8193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()', 'RandomForestClassifier()'], 'train accuracy': [78.31, 100.0, 100.0], 'test accuracy': [76.75, 98.25, 99.91], 'precision': [75.63, 96.77, 100.0], 'recall': [78.95, 99.82, 99.82]}\n"
     ]
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)\n",
    "populate_matrix(rf)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b046e0fb",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1854dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.940 (0.008)\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "# evaluate model\n",
    "cross_validate_model(gboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bcd606",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "599f67a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()', 'RandomForestClassifier()', 'GradientBoostingClassifier()'], 'train accuracy': [78.31, 100.0, 100.0, 94.61], 'test accuracy': [76.75, 98.25, 99.91, 94.12], 'precision': [75.63, 96.77, 100.0, 99.8], 'recall': [78.95, 99.82, 99.82, 88.42]}\n"
     ]
    }
   ],
   "source": [
    "gboost.fit(x_train,y_train)\n",
    "populate_matrix(gboost)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599c809",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54c29990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911 (0.011)\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "# evaluate model\n",
    "cross_validate_model(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12723c51",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4fb358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()', 'RandomForestClassifier()', 'GradientBoostingClassifier()', 'SVC()'], 'train accuracy': [78.31, 100.0, 100.0, 94.61, 92.59], 'test accuracy': [76.75, 98.25, 99.91, 94.12, 89.3], 'precision': [75.63, 96.77, 100.0, 99.8, 89.44], 'recall': [78.95, 99.82, 99.82, 88.42, 89.12]}\n"
     ]
    }
   ],
   "source": [
    "svm.fit(x_train,y_train)\n",
    "populate_matrix(svm)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85421df",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a11a252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(20,input_dim=x_train.shape[1],activation='relu'))\n",
    "ann_model.add(Dense(10,activation='relu'))\n",
    "ann_model.add(Dense(5,activation='relu'))\n",
    "ann_model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1d1b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595cfb3b",
   "metadata": {},
   "source": [
    "### Model TrainingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60bd5464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7970 - accuracy: 0.4851 - val_loss: 0.6560 - val_accuracy: 0.5825\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6366 - val_loss: 0.5846 - val_accuracy: 0.6842\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7160 - val_loss: 0.5247 - val_accuracy: 0.7456\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7800 - val_loss: 0.4754 - val_accuracy: 0.7772\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8118 - val_loss: 0.4397 - val_accuracy: 0.8140\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8395 - val_loss: 0.4133 - val_accuracy: 0.8307\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8502 - val_loss: 0.3975 - val_accuracy: 0.8368\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8568 - val_loss: 0.3854 - val_accuracy: 0.8421\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8614 - val_loss: 0.3769 - val_accuracy: 0.8518\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8697 - val_loss: 0.3695 - val_accuracy: 0.8526\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8741 - val_loss: 0.3619 - val_accuracy: 0.8596\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8783 - val_loss: 0.3594 - val_accuracy: 0.8570\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8779 - val_loss: 0.3523 - val_accuracy: 0.8614\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8811 - val_loss: 0.3504 - val_accuracy: 0.8640\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8816 - val_loss: 0.3474 - val_accuracy: 0.8623\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8840 - val_loss: 0.3428 - val_accuracy: 0.8684\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8860 - val_loss: 0.3406 - val_accuracy: 0.8640\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8895 - val_loss: 0.3379 - val_accuracy: 0.8719\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8879 - val_loss: 0.3385 - val_accuracy: 0.8640\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8882 - val_loss: 0.3322 - val_accuracy: 0.8746\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8930 - val_loss: 0.3291 - val_accuracy: 0.8702\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.8936 - val_loss: 0.3276 - val_accuracy: 0.8675\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8969 - val_loss: 0.3236 - val_accuracy: 0.8763\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8974 - val_loss: 0.3210 - val_accuracy: 0.8781\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.9002 - val_loss: 0.3174 - val_accuracy: 0.8798\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.9011 - val_loss: 0.3163 - val_accuracy: 0.8737\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.9018 - val_loss: 0.3158 - val_accuracy: 0.8719\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.9009 - val_loss: 0.3109 - val_accuracy: 0.8772\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.9037 - val_loss: 0.3094 - val_accuracy: 0.8825\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9064 - val_loss: 0.3109 - val_accuracy: 0.8772\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9081 - val_loss: 0.3071 - val_accuracy: 0.8825\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.9101 - val_loss: 0.3025 - val_accuracy: 0.8842\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.9101 - val_loss: 0.3015 - val_accuracy: 0.8825\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.9136 - val_loss: 0.3000 - val_accuracy: 0.8877\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9116 - val_loss: 0.3004 - val_accuracy: 0.8886\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9149 - val_loss: 0.3029 - val_accuracy: 0.8868\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9173 - val_loss: 0.2996 - val_accuracy: 0.8895\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.9171 - val_loss: 0.2972 - val_accuracy: 0.8921\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9178 - val_loss: 0.2943 - val_accuracy: 0.8895\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9158 - val_loss: 0.2993 - val_accuracy: 0.8860\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9191 - val_loss: 0.2894 - val_accuracy: 0.8947\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9180 - val_loss: 0.2937 - val_accuracy: 0.8904\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9167 - val_loss: 0.2881 - val_accuracy: 0.8921\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9193 - val_loss: 0.2873 - val_accuracy: 0.8956\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9195 - val_loss: 0.2859 - val_accuracy: 0.8930\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9202 - val_loss: 0.2854 - val_accuracy: 0.8921\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9213 - val_loss: 0.2837 - val_accuracy: 0.8982\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9197 - val_loss: 0.2839 - val_accuracy: 0.8947\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9221 - val_loss: 0.2842 - val_accuracy: 0.8939\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9186 - val_loss: 0.2801 - val_accuracy: 0.8991\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9224 - val_loss: 0.2800 - val_accuracy: 0.8947\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9217 - val_loss: 0.2812 - val_accuracy: 0.8930\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9215 - val_loss: 0.2758 - val_accuracy: 0.8947\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.9241 - val_loss: 0.2832 - val_accuracy: 0.8930\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.9237 - val_loss: 0.2797 - val_accuracy: 0.8921\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9241 - val_loss: 0.2772 - val_accuracy: 0.8974\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9243 - val_loss: 0.2762 - val_accuracy: 0.8930\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9246 - val_loss: 0.2708 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9254 - val_loss: 0.2706 - val_accuracy: 0.8982\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.9254 - val_loss: 0.2707 - val_accuracy: 0.9009\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.9287 - val_loss: 0.2688 - val_accuracy: 0.9018\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9307 - val_loss: 0.2679 - val_accuracy: 0.9000\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9296 - val_loss: 0.2696 - val_accuracy: 0.9009\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.9281 - val_loss: 0.2704 - val_accuracy: 0.8965\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9309 - val_loss: 0.2665 - val_accuracy: 0.9009\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9303 - val_loss: 0.2672 - val_accuracy: 0.8965\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9311 - val_loss: 0.2646 - val_accuracy: 0.9018\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9303 - val_loss: 0.2605 - val_accuracy: 0.9053\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9311 - val_loss: 0.2592 - val_accuracy: 0.9053\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9320 - val_loss: 0.2606 - val_accuracy: 0.9026\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9340 - val_loss: 0.2605 - val_accuracy: 0.9009\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9329 - val_loss: 0.2581 - val_accuracy: 0.9000\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9336 - val_loss: 0.2603 - val_accuracy: 0.9061\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9340 - val_loss: 0.2597 - val_accuracy: 0.9009\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9342 - val_loss: 0.2555 - val_accuracy: 0.9053\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9349 - val_loss: 0.2573 - val_accuracy: 0.9053\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9373 - val_loss: 0.2538 - val_accuracy: 0.9070\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9338 - val_loss: 0.2545 - val_accuracy: 0.9026\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1719 - accuracy: 0.9346 - val_loss: 0.2530 - val_accuracy: 0.9079\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9364 - val_loss: 0.2526 - val_accuracy: 0.9026\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9379 - val_loss: 0.2567 - val_accuracy: 0.9035\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9379 - val_loss: 0.2503 - val_accuracy: 0.9044\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9388 - val_loss: 0.2629 - val_accuracy: 0.9070\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9377 - val_loss: 0.2506 - val_accuracy: 0.9114\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9393 - val_loss: 0.2486 - val_accuracy: 0.9114\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9393 - val_loss: 0.2468 - val_accuracy: 0.9123\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9393 - val_loss: 0.2488 - val_accuracy: 0.9070\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9390 - val_loss: 0.2498 - val_accuracy: 0.9088\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9417 - val_loss: 0.2482 - val_accuracy: 0.9123\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9404 - val_loss: 0.2442 - val_accuracy: 0.9132\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9430 - val_loss: 0.2447 - val_accuracy: 0.9105\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1576 - accuracy: 0.9421 - val_loss: 0.2465 - val_accuracy: 0.9096\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9425 - val_loss: 0.2441 - val_accuracy: 0.9088\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9417 - val_loss: 0.2449 - val_accuracy: 0.9158\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9428 - val_loss: 0.2437 - val_accuracy: 0.9114\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9445 - val_loss: 0.2421 - val_accuracy: 0.9158\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9454 - val_loss: 0.2484 - val_accuracy: 0.9184\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9461 - val_loss: 0.2413 - val_accuracy: 0.9140\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9471 - val_loss: 0.2408 - val_accuracy: 0.9140\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9463 - val_loss: 0.2420 - val_accuracy: 0.9140\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9471 - val_loss: 0.2513 - val_accuracy: 0.9193\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9467 - val_loss: 0.2411 - val_accuracy: 0.9175\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9469 - val_loss: 0.2459 - val_accuracy: 0.9193\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9476 - val_loss: 0.2385 - val_accuracy: 0.9167\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9489 - val_loss: 0.2425 - val_accuracy: 0.9175\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9485 - val_loss: 0.2412 - val_accuracy: 0.9202\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9511 - val_loss: 0.2417 - val_accuracy: 0.9211\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9474 - val_loss: 0.2453 - val_accuracy: 0.9211\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9520 - val_loss: 0.2406 - val_accuracy: 0.9202\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9537 - val_loss: 0.2442 - val_accuracy: 0.9193\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9520 - val_loss: 0.2422 - val_accuracy: 0.9228\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9529 - val_loss: 0.2437 - val_accuracy: 0.9219\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9529 - val_loss: 0.2397 - val_accuracy: 0.9228\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9524 - val_loss: 0.2389 - val_accuracy: 0.9219\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9533 - val_loss: 0.2331 - val_accuracy: 0.9237\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9537 - val_loss: 0.2374 - val_accuracy: 0.9175\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: 0.2349 - val_accuracy: 0.9175\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9522 - val_loss: 0.2475 - val_accuracy: 0.9219\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9529 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9548 - val_loss: 0.2379 - val_accuracy: 0.9228\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9531 - val_loss: 0.2298 - val_accuracy: 0.9219\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9546 - val_loss: 0.2383 - val_accuracy: 0.9237\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9526 - val_loss: 0.2313 - val_accuracy: 0.9219\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9559 - val_loss: 0.2317 - val_accuracy: 0.9219\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9566 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9555 - val_loss: 0.2324 - val_accuracy: 0.9237\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9566 - val_loss: 0.2362 - val_accuracy: 0.9193\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9579 - val_loss: 0.2330 - val_accuracy: 0.9202\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9550 - val_loss: 0.2334 - val_accuracy: 0.9158\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9559 - val_loss: 0.2321 - val_accuracy: 0.9254\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9561 - val_loss: 0.2398 - val_accuracy: 0.9211\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9590 - val_loss: 0.2286 - val_accuracy: 0.9228\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9575 - val_loss: 0.2367 - val_accuracy: 0.9237\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9575 - val_loss: 0.2314 - val_accuracy: 0.9254\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9572 - val_loss: 0.2339 - val_accuracy: 0.9228\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9559 - val_loss: 0.2325 - val_accuracy: 0.9211\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9588 - val_loss: 0.2258 - val_accuracy: 0.9202\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9592 - val_loss: 0.2306 - val_accuracy: 0.9263\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9601 - val_loss: 0.2315 - val_accuracy: 0.9228\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9579 - val_loss: 0.2281 - val_accuracy: 0.9237\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9577 - val_loss: 0.2313 - val_accuracy: 0.9289\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9594 - val_loss: 0.2376 - val_accuracy: 0.9281\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9586 - val_loss: 0.2324 - val_accuracy: 0.9263\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9603 - val_loss: 0.2347 - val_accuracy: 0.9211\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9594 - val_loss: 0.2353 - val_accuracy: 0.9219\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9592 - val_loss: 0.2335 - val_accuracy: 0.9263\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9596 - val_loss: 0.2325 - val_accuracy: 0.9254\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9601 - val_loss: 0.2396 - val_accuracy: 0.9237\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9592 - val_loss: 0.2410 - val_accuracy: 0.9228\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9616 - val_loss: 0.2316 - val_accuracy: 0.9211\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9610 - val_loss: 0.2377 - val_accuracy: 0.9193\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9607 - val_loss: 0.2355 - val_accuracy: 0.9228\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9612 - val_loss: 0.2351 - val_accuracy: 0.9219\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9612 - val_loss: 0.2375 - val_accuracy: 0.9263\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9601 - val_loss: 0.2309 - val_accuracy: 0.9237\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9607 - val_loss: 0.2307 - val_accuracy: 0.9246\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9614 - val_loss: 0.2301 - val_accuracy: 0.9211\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9610 - val_loss: 0.2372 - val_accuracy: 0.9219\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9599 - val_loss: 0.2325 - val_accuracy: 0.9246\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9623 - val_loss: 0.2412 - val_accuracy: 0.9219\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9605 - val_loss: 0.2381 - val_accuracy: 0.9237\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9636 - val_loss: 0.2324 - val_accuracy: 0.9211\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9607 - val_loss: 0.2308 - val_accuracy: 0.9263\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9623 - val_loss: 0.2369 - val_accuracy: 0.9237\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9623 - val_loss: 0.2280 - val_accuracy: 0.9281\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9627 - val_loss: 0.2300 - val_accuracy: 0.9237\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9623 - val_loss: 0.2445 - val_accuracy: 0.9246\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9625 - val_loss: 0.2337 - val_accuracy: 0.9228\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9621 - val_loss: 0.2460 - val_accuracy: 0.9272\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9636 - val_loss: 0.2450 - val_accuracy: 0.9254\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9616 - val_loss: 0.2370 - val_accuracy: 0.9219\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9634 - val_loss: 0.2379 - val_accuracy: 0.9289\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9629 - val_loss: 0.2426 - val_accuracy: 0.9289\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9625 - val_loss: 0.2326 - val_accuracy: 0.9263\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9621 - val_loss: 0.2367 - val_accuracy: 0.9281\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9634 - val_loss: 0.2387 - val_accuracy: 0.9246\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9614 - val_loss: 0.2543 - val_accuracy: 0.9281\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9643 - val_loss: 0.2535 - val_accuracy: 0.9246\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.2307 - val_accuracy: 0.9228\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9629 - val_loss: 0.2366 - val_accuracy: 0.9281\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9632 - val_loss: 0.2505 - val_accuracy: 0.9325\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9649 - val_loss: 0.2433 - val_accuracy: 0.9254\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9632 - val_loss: 0.2377 - val_accuracy: 0.9298\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9643 - val_loss: 0.2512 - val_accuracy: 0.9272\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9640 - val_loss: 0.2428 - val_accuracy: 0.9298\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9654 - val_loss: 0.2441 - val_accuracy: 0.9316\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9638 - val_loss: 0.2404 - val_accuracy: 0.9316\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9649 - val_loss: 0.2375 - val_accuracy: 0.9289\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9658 - val_loss: 0.2446 - val_accuracy: 0.9298\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9627 - val_loss: 0.2436 - val_accuracy: 0.9263\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9649 - val_loss: 0.2368 - val_accuracy: 0.9263\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9616 - val_loss: 0.2506 - val_accuracy: 0.9316\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9643 - val_loss: 0.2460 - val_accuracy: 0.9325\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9662 - val_loss: 0.2560 - val_accuracy: 0.9298\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9634 - val_loss: 0.2539 - val_accuracy: 0.9316\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9654 - val_loss: 0.2427 - val_accuracy: 0.9316\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9669 - val_loss: 0.2502 - val_accuracy: 0.9333\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9660 - val_loss: 0.2419 - val_accuracy: 0.9298\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9654 - val_loss: 0.2445 - val_accuracy: 0.9298\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9654 - val_loss: 0.2378 - val_accuracy: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8c2ac4dc0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.fit(x_train,y_train,batch_size=100,epochs=200,validation_data=(x_test,y_test),shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622ea2b",
   "metadata": {},
   "source": [
    "## convertiing probabilities to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6713a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ann_model.predict(x_train)\n",
    "for i in range(0,len(y_pred_train)):\n",
    "    if y_pred_train[i]>=.5:\n",
    "        y_pred_train[i] = 1\n",
    "    else:\n",
    "        y_pred_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f157c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = ann_model.predict(x_test)\n",
    "for i in range(0,len(y_pred_test)):\n",
    "    if y_pred_test[i]>=.5:\n",
    "        y_pred_test[i] = 1\n",
    "    else:\n",
    "        y_pred_test[i] = 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "822125f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict[\"model\"].append('ANN')\n",
    "my_dict[\"train accuracy\"].append(round(accuracy_score(y_train,y_pred_train)*100,2))\n",
    "my_dict[\"test accuracy\"].append(round(accuracy_score(y_test,y_pred_test)*100,2))\n",
    "my_dict[\"precision\"].append(round(precision_score(y_test,y_pred_test)*100,2))\n",
    "my_dict[\"recall\"].append(round(recall_score(y_test,y_pred_test)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f298133",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21cfdd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795 (0.018)\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "# evaluate model\n",
    "cross_validate_model(gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "400cf46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()', 'RandomForestClassifier()', 'GradientBoostingClassifier()', 'SVC()', 'ANN', 'GaussianNB()'], 'train accuracy': [78.31, 100.0, 100.0, 94.61, 92.59, 96.93, 79.78], 'test accuracy': [76.75, 98.25, 99.91, 94.12, 89.3, 93.25, 78.95], 'precision': [75.63, 96.77, 100.0, 99.8, 89.44, 91.99, 79.26], 'recall': [78.95, 99.82, 99.82, 88.42, 89.12, 94.74, 78.42]}\n"
     ]
    }
   ],
   "source": [
    "gnb.fit(x_train,y_train)\n",
    "populate_matrix(gnb)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649cc000",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "#### Adding performance metrics of xgboost manually, i implemented the same in seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd13886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict[\"model\"].append('XGBClassifier()')\n",
    "my_dict[\"train accuracy\"].append(90.2)\n",
    "my_dict[\"test accuracy\"].append(90.76)\n",
    "my_dict[\"precision\"].append(93.52)\n",
    "my_dict[\"recall\"].append(87.62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc54fde6",
   "metadata": {},
   "source": [
    "## Final performance matrix of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "044041ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.91</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>100.00</td>\n",
       "      <td>98.25</td>\n",
       "      <td>96.77</td>\n",
       "      <td>99.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>94.61</td>\n",
       "      <td>94.12</td>\n",
       "      <td>99.80</td>\n",
       "      <td>88.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANN</td>\n",
       "      <td>96.93</td>\n",
       "      <td>93.25</td>\n",
       "      <td>91.99</td>\n",
       "      <td>94.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier()</td>\n",
       "      <td>90.20</td>\n",
       "      <td>90.76</td>\n",
       "      <td>93.52</td>\n",
       "      <td>87.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>92.59</td>\n",
       "      <td>89.30</td>\n",
       "      <td>89.44</td>\n",
       "      <td>89.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>79.78</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.26</td>\n",
       "      <td>78.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>78.31</td>\n",
       "      <td>76.75</td>\n",
       "      <td>75.63</td>\n",
       "      <td>78.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  train accuracy  test accuracy  precision  \\\n",
       "2      RandomForestClassifier()          100.00          99.91     100.00   \n",
       "1      DecisionTreeClassifier()          100.00          98.25      96.77   \n",
       "3  GradientBoostingClassifier()           94.61          94.12      99.80   \n",
       "5                           ANN           96.93          93.25      91.99   \n",
       "7               XGBClassifier()           90.20          90.76      93.52   \n",
       "4                         SVC()           92.59          89.30      89.44   \n",
       "6                  GaussianNB()           79.78          78.95      79.26   \n",
       "0          LogisticRegression()           78.31          76.75      75.63   \n",
       "\n",
       "   recall  \n",
       "2   99.82  \n",
       "1   99.82  \n",
       "3   88.42  \n",
       "5   94.74  \n",
       "7   87.62  \n",
       "4   89.12  \n",
       "6   78.42  \n",
       "0   78.95  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(my_dict).sort_values(by='test accuracy',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
