{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33639174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,RepeatedStratifiedKFold,cross_val_score\n",
    "from numpy import mean,std\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5117fd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>voice_mail_messages</th>\n",
       "      <th>day_mins</th>\n",
       "      <th>evening_mins</th>\n",
       "      <th>night_mins</th>\n",
       "      <th>international_mins</th>\n",
       "      <th>customer_service_calls</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>day_calls</th>\n",
       "      <th>day_charge</th>\n",
       "      <th>evening_calls</th>\n",
       "      <th>evening_charge</th>\n",
       "      <th>night_calls</th>\n",
       "      <th>night_charge</th>\n",
       "      <th>international_calls</th>\n",
       "      <th>international_charge</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>197.4</td>\n",
       "      <td>244.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>75.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>195.5</td>\n",
       "      <td>254.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>59.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>121.2</td>\n",
       "      <td>162.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>62.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>61.9</td>\n",
       "      <td>196.9</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>66.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>148.3</td>\n",
       "      <td>186.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>52.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  voice_mail_plan  voice_mail_messages  day_mins  \\\n",
       "0             128                1                   25     265.1   \n",
       "1             107                1                   26     161.6   \n",
       "2             137                0                    0     243.4   \n",
       "3              84                0                    0     299.4   \n",
       "4              75                0                    0     166.7   \n",
       "\n",
       "   evening_mins  night_mins  international_mins  customer_service_calls  \\\n",
       "0         197.4       244.7                10.0                       1   \n",
       "1         195.5       254.4                13.7                       1   \n",
       "2         121.2       162.6                12.2                       0   \n",
       "3          61.9       196.9                 6.6                       2   \n",
       "4         148.3       186.9                10.1                       3   \n",
       "\n",
       "   international_plan  day_calls  day_charge  evening_calls  evening_charge  \\\n",
       "0                   0        110       45.07             99           16.78   \n",
       "1                   0        123       27.47            103           16.62   \n",
       "2                   0        114       41.38            110           10.30   \n",
       "3                   1         71       50.90             88            5.26   \n",
       "4                   1        113       28.34            122           12.61   \n",
       "\n",
       "   night_calls  night_charge  international_calls  international_charge  \\\n",
       "0           91         11.01                    3                  2.70   \n",
       "1          103         11.45                    3                  3.70   \n",
       "2          104          7.32                    5                  3.29   \n",
       "3           89          8.86                    7                  1.78   \n",
       "4          121          8.41                    3                  2.73   \n",
       "\n",
       "   total_charge  churn  \n",
       "0         75.56      0  \n",
       "1         59.24      0  \n",
       "2         62.29      0  \n",
       "3         66.80      0  \n",
       "4         52.09      0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/oversampled_data.csv')\n",
    "del data['Unnamed: 0']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321be1d",
   "metadata": {},
   "source": [
    "### Scaling an dseperating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "54098f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3333, 18), (3333, 1))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scr = StandardScaler()\n",
    "X = data.drop(labels='churn',axis=1)\n",
    "cols = X.columns\n",
    "X = pd.DataFrame(std_scr.fit_transform(X))\n",
    "X.columns = cols\n",
    "y = data[['churn']]\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4ddef",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f870bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=True,random_state=12,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d3597",
   "metadata": {},
   "source": [
    "### Dict to store performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "533d57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'model':[], 'accuracy': [],'precision':[],'recall':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc034f75",
   "metadata": {},
   "source": [
    "### Method to predit and calculate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe11755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_matrix(fittedModel):\n",
    "    y_pred = fittedModel.predict(x_test)\n",
    "    accuracy = round(accuracy_score(y_test,y_pred)*100,2)\n",
    "    precision = round(precision_score(y_test,y_pred)*100,2)\n",
    "    recall = round(recall_score(y_test,y_pred)*100,2)\n",
    "    model = str(fittedModel)\n",
    "    my_dict[\"model\"].append(model)\n",
    "    my_dict[\"accuracy\"].append(accuracy)\n",
    "    my_dict[\"precision\"].append(precision)\n",
    "    my_dict[\"recall\"].append(recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350d0ca",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10c5c4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "logistic = LogisticRegression()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(estimator=logistic,X=X,y=y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b6a67",
   "metadata": {},
   "source": [
    "### Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7dd41f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()'], 'accuracy': [76.75], 'precision': [75.63], 'recall': [78.95]}\n"
     ]
    }
   ],
   "source": [
    "logistic.fit(x_train,y_train)\n",
    "populate_matrix(logistic)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f70f5",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c340f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.983 (0.005)\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(estimator=dtree,X=X,y=y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc4fe3",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5da236e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()'], 'accuracy': [76.75, 98.42], 'precision': [75.63, 97.1], 'recall': [78.95, 99.82]}\n"
     ]
    }
   ],
   "source": [
    "dtree.fit(x_train,y_train)\n",
    "populate_matrix(dtree)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afc17c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45529565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999 (0.001)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(estimator=rf,X=X,y=y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88c177",
   "metadata": {},
   "source": [
    "### Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "77af8193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()', 'RandomForestClassifier()'], 'accuracy': [76.75, 98.42, 99.91], 'precision': [75.63, 97.1, 100.0], 'recall': [78.95, 99.82, 99.82]}\n"
     ]
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)\n",
    "populate_matrix(rf)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b046e0fb",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1854dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.940 (0.008)\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(estimator=gboost,X=X,y=y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bcd606",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "599f67a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()', 'RandomForestClassifier()', 'GradientBoostingClassifier()'], 'accuracy': [76.75, 98.42, 99.91, 94.12], 'precision': [75.63, 97.1, 100.0, 99.8], 'recall': [78.95, 99.82, 99.82, 88.42]}\n"
     ]
    }
   ],
   "source": [
    "gboost.fit(x_train,y_train)\n",
    "populate_matrix(gboost)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599c809",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "54c29990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911 (0.011)\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(estimator=svm,X=X,y=y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12723c51",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4fb358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['LogisticRegression()', 'DecisionTreeClassifier()', 'RandomForestClassifier()', 'GradientBoostingClassifier()', 'SVC()'], 'accuracy': [76.75, 98.42, 99.91, 94.12, 89.3], 'precision': [75.63, 97.1, 100.0, 99.8, 89.44], 'recall': [78.95, 99.82, 99.82, 88.42, 89.12]}\n"
     ]
    }
   ],
   "source": [
    "svm.fit(x_train,y_train)\n",
    "populate_matrix(svm)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85421df",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a11a252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(20,input_dim=x_train.shape[1],activation='relu'))\n",
    "ann_model.add(Dense(10,activation='relu'))\n",
    "ann_model.add(Dense(5,activation='relu'))\n",
    "ann_model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f1d1b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595cfb3b",
   "metadata": {},
   "source": [
    "### Model TrainingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60bd5464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5884 - val_loss: 0.6156 - val_accuracy: 0.6825\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7123 - val_loss: 0.5287 - val_accuracy: 0.7526\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7728 - val_loss: 0.4620 - val_accuracy: 0.7904\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8151 - val_loss: 0.4222 - val_accuracy: 0.8140\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8364 - val_loss: 0.3971 - val_accuracy: 0.8325\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8471 - val_loss: 0.3845 - val_accuracy: 0.8509\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8550 - val_loss: 0.3744 - val_accuracy: 0.8535\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8654 - val_loss: 0.3668 - val_accuracy: 0.8518\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8693 - val_loss: 0.3603 - val_accuracy: 0.8553\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8730 - val_loss: 0.3547 - val_accuracy: 0.8605\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8789 - val_loss: 0.3504 - val_accuracy: 0.8623\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8818 - val_loss: 0.3457 - val_accuracy: 0.8632\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8851 - val_loss: 0.3403 - val_accuracy: 0.8684\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8866 - val_loss: 0.3366 - val_accuracy: 0.8675\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8877 - val_loss: 0.3321 - val_accuracy: 0.8667\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8864 - val_loss: 0.3283 - val_accuracy: 0.8693\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8882 - val_loss: 0.3254 - val_accuracy: 0.8746\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8904 - val_loss: 0.3219 - val_accuracy: 0.8763\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2864 - accuracy: 0.8899 - val_loss: 0.3216 - val_accuracy: 0.8719\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8925 - val_loss: 0.3164 - val_accuracy: 0.8763\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2790 - accuracy: 0.8934 - val_loss: 0.3126 - val_accuracy: 0.8737\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 0.8947 - val_loss: 0.3115 - val_accuracy: 0.8772\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8963 - val_loss: 0.3064 - val_accuracy: 0.8754\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8956 - val_loss: 0.3086 - val_accuracy: 0.8746\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8971 - val_loss: 0.3057 - val_accuracy: 0.8798\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8982 - val_loss: 0.3027 - val_accuracy: 0.8807\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.9026 - val_loss: 0.2987 - val_accuracy: 0.8816\n",
      "Epoch 28/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.9018 - val_loss: 0.2968 - val_accuracy: 0.8833\n",
      "Epoch 29/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.9053 - val_loss: 0.2950 - val_accuracy: 0.8816\n",
      "Epoch 30/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.9044 - val_loss: 0.2930 - val_accuracy: 0.8842\n",
      "Epoch 31/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.9050 - val_loss: 0.2965 - val_accuracy: 0.8825\n",
      "Epoch 32/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9059 - val_loss: 0.2911 - val_accuracy: 0.8833\n",
      "Epoch 33/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.9072 - val_loss: 0.2871 - val_accuracy: 0.8833\n",
      "Epoch 34/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9110 - val_loss: 0.2834 - val_accuracy: 0.8842\n",
      "Epoch 35/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9132 - val_loss: 0.2786 - val_accuracy: 0.8877\n",
      "Epoch 36/200\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9145 - val_loss: 0.2794 - val_accuracy: 0.8904\n",
      "Epoch 37/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9143 - val_loss: 0.2817 - val_accuracy: 0.8868\n",
      "Epoch 38/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9167 - val_loss: 0.2742 - val_accuracy: 0.8912\n",
      "Epoch 39/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9160 - val_loss: 0.2783 - val_accuracy: 0.8877\n",
      "Epoch 40/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9164 - val_loss: 0.2728 - val_accuracy: 0.8912\n",
      "Epoch 41/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9191 - val_loss: 0.2709 - val_accuracy: 0.8921\n",
      "Epoch 42/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9175 - val_loss: 0.2709 - val_accuracy: 0.8939\n",
      "Epoch 43/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.9200 - val_loss: 0.2673 - val_accuracy: 0.8965\n",
      "Epoch 44/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.9195 - val_loss: 0.2674 - val_accuracy: 0.8947\n",
      "Epoch 45/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9186 - val_loss: 0.2638 - val_accuracy: 0.8974\n",
      "Epoch 46/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9235 - val_loss: 0.2644 - val_accuracy: 0.8991\n",
      "Epoch 47/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9232 - val_loss: 0.2702 - val_accuracy: 0.8930\n",
      "Epoch 48/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9182 - val_loss: 0.2656 - val_accuracy: 0.8956\n",
      "Epoch 49/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9246 - val_loss: 0.2592 - val_accuracy: 0.9000\n",
      "Epoch 50/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9221 - val_loss: 0.2634 - val_accuracy: 0.8947\n",
      "Epoch 51/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9263 - val_loss: 0.2583 - val_accuracy: 0.9035\n",
      "Epoch 52/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9270 - val_loss: 0.2554 - val_accuracy: 0.9035\n",
      "Epoch 53/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9289 - val_loss: 0.2541 - val_accuracy: 0.9044\n",
      "Epoch 54/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.9287 - val_loss: 0.2545 - val_accuracy: 0.9026\n",
      "Epoch 55/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9309 - val_loss: 0.2587 - val_accuracy: 0.9061\n",
      "Epoch 56/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9318 - val_loss: 0.2515 - val_accuracy: 0.9070\n",
      "Epoch 57/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9349 - val_loss: 0.2523 - val_accuracy: 0.9158\n",
      "Epoch 58/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9336 - val_loss: 0.2513 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9344 - val_loss: 0.2604 - val_accuracy: 0.9114\n",
      "Epoch 60/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9351 - val_loss: 0.2511 - val_accuracy: 0.9088\n",
      "Epoch 61/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9364 - val_loss: 0.2488 - val_accuracy: 0.9140\n",
      "Epoch 62/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9342 - val_loss: 0.2591 - val_accuracy: 0.9096\n",
      "Epoch 63/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9384 - val_loss: 0.2511 - val_accuracy: 0.9149\n",
      "Epoch 64/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9364 - val_loss: 0.2529 - val_accuracy: 0.9175\n",
      "Epoch 65/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9375 - val_loss: 0.2502 - val_accuracy: 0.9132\n",
      "Epoch 66/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9371 - val_loss: 0.2470 - val_accuracy: 0.9184\n",
      "Epoch 67/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9390 - val_loss: 0.2424 - val_accuracy: 0.9184\n",
      "Epoch 68/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9395 - val_loss: 0.2518 - val_accuracy: 0.9114\n",
      "Epoch 69/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9410 - val_loss: 0.2431 - val_accuracy: 0.9175\n",
      "Epoch 70/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9443 - val_loss: 0.2443 - val_accuracy: 0.9184\n",
      "Epoch 71/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9421 - val_loss: 0.2442 - val_accuracy: 0.9132\n",
      "Epoch 72/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9430 - val_loss: 0.2414 - val_accuracy: 0.9158\n",
      "Epoch 73/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9410 - val_loss: 0.2449 - val_accuracy: 0.9158\n",
      "Epoch 74/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9436 - val_loss: 0.2493 - val_accuracy: 0.9228\n",
      "Epoch 75/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9436 - val_loss: 0.2464 - val_accuracy: 0.9184\n",
      "Epoch 76/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9436 - val_loss: 0.2532 - val_accuracy: 0.9202\n",
      "Epoch 77/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9467 - val_loss: 0.2434 - val_accuracy: 0.9175\n",
      "Epoch 78/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9463 - val_loss: 0.2467 - val_accuracy: 0.9167\n",
      "Epoch 79/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9454 - val_loss: 0.2530 - val_accuracy: 0.9132\n",
      "Epoch 80/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9461 - val_loss: 0.2489 - val_accuracy: 0.9219\n",
      "Epoch 81/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9476 - val_loss: 0.2509 - val_accuracy: 0.9202\n",
      "Epoch 82/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9491 - val_loss: 0.2411 - val_accuracy: 0.9193\n",
      "Epoch 83/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9485 - val_loss: 0.2468 - val_accuracy: 0.9219\n",
      "Epoch 84/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9493 - val_loss: 0.2436 - val_accuracy: 0.9202\n",
      "Epoch 85/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9485 - val_loss: 0.2471 - val_accuracy: 0.9149\n",
      "Epoch 86/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9496 - val_loss: 0.2458 - val_accuracy: 0.9246\n",
      "Epoch 87/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9522 - val_loss: 0.2487 - val_accuracy: 0.9211\n",
      "Epoch 88/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9502 - val_loss: 0.2448 - val_accuracy: 0.9237\n",
      "Epoch 89/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9485 - val_loss: 0.2431 - val_accuracy: 0.9211\n",
      "Epoch 90/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9500 - val_loss: 0.2428 - val_accuracy: 0.9193\n",
      "Epoch 91/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9509 - val_loss: 0.2492 - val_accuracy: 0.9237\n",
      "Epoch 92/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9509 - val_loss: 0.2488 - val_accuracy: 0.9246\n",
      "Epoch 93/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9546 - val_loss: 0.2488 - val_accuracy: 0.9219\n",
      "Epoch 94/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9539 - val_loss: 0.2528 - val_accuracy: 0.9237\n",
      "Epoch 95/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9544 - val_loss: 0.2438 - val_accuracy: 0.9246\n",
      "Epoch 96/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9531 - val_loss: 0.2464 - val_accuracy: 0.9175\n",
      "Epoch 97/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9553 - val_loss: 0.2461 - val_accuracy: 0.9202\n",
      "Epoch 98/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9553 - val_loss: 0.2488 - val_accuracy: 0.9228\n",
      "Epoch 99/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9557 - val_loss: 0.2460 - val_accuracy: 0.9254\n",
      "Epoch 100/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9570 - val_loss: 0.2533 - val_accuracy: 0.9246\n",
      "Epoch 101/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9564 - val_loss: 0.2450 - val_accuracy: 0.9202\n",
      "Epoch 102/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9539 - val_loss: 0.2523 - val_accuracy: 0.9202\n",
      "Epoch 103/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9570 - val_loss: 0.2574 - val_accuracy: 0.9202\n",
      "Epoch 104/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9577 - val_loss: 0.2457 - val_accuracy: 0.9167\n",
      "Epoch 105/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9550 - val_loss: 0.2500 - val_accuracy: 0.9167\n",
      "Epoch 106/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9550 - val_loss: 0.2514 - val_accuracy: 0.9228\n",
      "Epoch 107/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9577 - val_loss: 0.2584 - val_accuracy: 0.9202\n",
      "Epoch 108/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9557 - val_loss: 0.2483 - val_accuracy: 0.9246\n",
      "Epoch 109/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9579 - val_loss: 0.2435 - val_accuracy: 0.9202\n",
      "Epoch 110/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9583 - val_loss: 0.2626 - val_accuracy: 0.9246\n",
      "Epoch 111/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9603 - val_loss: 0.2483 - val_accuracy: 0.9228\n",
      "Epoch 112/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9596 - val_loss: 0.2531 - val_accuracy: 0.9211\n",
      "Epoch 113/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9583 - val_loss: 0.2611 - val_accuracy: 0.9184\n",
      "Epoch 114/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9566 - val_loss: 0.2479 - val_accuracy: 0.9167\n",
      "Epoch 115/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9581 - val_loss: 0.2495 - val_accuracy: 0.9184\n",
      "Epoch 116/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9621 - val_loss: 0.2538 - val_accuracy: 0.9246\n",
      "Epoch 117/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9605 - val_loss: 0.2464 - val_accuracy: 0.9158\n",
      "Epoch 118/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9610 - val_loss: 0.2564 - val_accuracy: 0.9211\n",
      "Epoch 119/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9607 - val_loss: 0.2545 - val_accuracy: 0.9228\n",
      "Epoch 120/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9610 - val_loss: 0.2490 - val_accuracy: 0.9175\n",
      "Epoch 121/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9621 - val_loss: 0.2784 - val_accuracy: 0.9193\n",
      "Epoch 122/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9636 - val_loss: 0.2502 - val_accuracy: 0.9167\n",
      "Epoch 123/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9614 - val_loss: 0.2629 - val_accuracy: 0.9211\n",
      "Epoch 124/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9634 - val_loss: 0.2591 - val_accuracy: 0.9246\n",
      "Epoch 125/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9616 - val_loss: 0.2538 - val_accuracy: 0.9246\n",
      "Epoch 126/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9627 - val_loss: 0.2663 - val_accuracy: 0.9228\n",
      "Epoch 127/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9616 - val_loss: 0.2591 - val_accuracy: 0.9246\n",
      "Epoch 128/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9643 - val_loss: 0.2635 - val_accuracy: 0.9175\n",
      "Epoch 129/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9621 - val_loss: 0.2620 - val_accuracy: 0.9219\n",
      "Epoch 130/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9629 - val_loss: 0.2670 - val_accuracy: 0.9202\n",
      "Epoch 131/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9645 - val_loss: 0.2518 - val_accuracy: 0.9246\n",
      "Epoch 132/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9654 - val_loss: 0.2564 - val_accuracy: 0.9202\n",
      "Epoch 133/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9651 - val_loss: 0.2633 - val_accuracy: 0.9193\n",
      "Epoch 134/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9669 - val_loss: 0.2701 - val_accuracy: 0.9184\n",
      "Epoch 135/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9654 - val_loss: 0.2618 - val_accuracy: 0.9228\n",
      "Epoch 136/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9667 - val_loss: 0.2598 - val_accuracy: 0.9193\n",
      "Epoch 137/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9680 - val_loss: 0.2714 - val_accuracy: 0.9193\n",
      "Epoch 138/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9647 - val_loss: 0.2574 - val_accuracy: 0.9193\n",
      "Epoch 139/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9667 - val_loss: 0.2574 - val_accuracy: 0.9254\n",
      "Epoch 140/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9678 - val_loss: 0.2590 - val_accuracy: 0.9272\n",
      "Epoch 141/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9682 - val_loss: 0.2582 - val_accuracy: 0.9263\n",
      "Epoch 142/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9662 - val_loss: 0.2513 - val_accuracy: 0.9237\n",
      "Epoch 143/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9664 - val_loss: 0.2762 - val_accuracy: 0.9228\n",
      "Epoch 144/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9680 - val_loss: 0.2581 - val_accuracy: 0.9272\n",
      "Epoch 145/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9689 - val_loss: 0.2618 - val_accuracy: 0.9246\n",
      "Epoch 146/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9658 - val_loss: 0.2731 - val_accuracy: 0.9193\n",
      "Epoch 147/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9680 - val_loss: 0.2588 - val_accuracy: 0.9298\n",
      "Epoch 148/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9689 - val_loss: 0.2688 - val_accuracy: 0.9219\n",
      "Epoch 149/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9715 - val_loss: 0.2607 - val_accuracy: 0.9254\n",
      "Epoch 150/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9667 - val_loss: 0.2745 - val_accuracy: 0.9281\n",
      "Epoch 151/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9691 - val_loss: 0.2626 - val_accuracy: 0.9237\n",
      "Epoch 152/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9664 - val_loss: 0.2626 - val_accuracy: 0.9254\n",
      "Epoch 153/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9702 - val_loss: 0.2774 - val_accuracy: 0.9281\n",
      "Epoch 154/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9704 - val_loss: 0.2672 - val_accuracy: 0.9263\n",
      "Epoch 155/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9695 - val_loss: 0.2746 - val_accuracy: 0.9237\n",
      "Epoch 156/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9695 - val_loss: 0.2620 - val_accuracy: 0.9272\n",
      "Epoch 157/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9669 - val_loss: 0.2705 - val_accuracy: 0.9281\n",
      "Epoch 158/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9713 - val_loss: 0.2660 - val_accuracy: 0.9316\n",
      "Epoch 159/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9713 - val_loss: 0.2650 - val_accuracy: 0.9316\n",
      "Epoch 160/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9728 - val_loss: 0.2707 - val_accuracy: 0.9342\n",
      "Epoch 161/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9691 - val_loss: 0.2821 - val_accuracy: 0.9281\n",
      "Epoch 162/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9704 - val_loss: 0.2679 - val_accuracy: 0.9316\n",
      "Epoch 163/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9708 - val_loss: 0.2646 - val_accuracy: 0.9298\n",
      "Epoch 164/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9724 - val_loss: 0.2756 - val_accuracy: 0.9289\n",
      "Epoch 165/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9724 - val_loss: 0.2551 - val_accuracy: 0.9193\n",
      "Epoch 166/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9717 - val_loss: 0.2685 - val_accuracy: 0.9272\n",
      "Epoch 167/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9732 - val_loss: 0.2848 - val_accuracy: 0.9316\n",
      "Epoch 168/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9719 - val_loss: 0.2864 - val_accuracy: 0.9298\n",
      "Epoch 169/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9719 - val_loss: 0.2934 - val_accuracy: 0.9298\n",
      "Epoch 170/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9728 - val_loss: 0.2817 - val_accuracy: 0.9333\n",
      "Epoch 171/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9728 - val_loss: 0.2617 - val_accuracy: 0.9307\n",
      "Epoch 172/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9735 - val_loss: 0.2812 - val_accuracy: 0.9351\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9741 - val_loss: 0.2814 - val_accuracy: 0.9333\n",
      "Epoch 174/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9746 - val_loss: 0.2945 - val_accuracy: 0.9316\n",
      "Epoch 175/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9748 - val_loss: 0.2770 - val_accuracy: 0.9316\n",
      "Epoch 176/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9754 - val_loss: 0.2713 - val_accuracy: 0.9316\n",
      "Epoch 177/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9741 - val_loss: 0.2836 - val_accuracy: 0.9316\n",
      "Epoch 178/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9763 - val_loss: 0.2963 - val_accuracy: 0.9351\n",
      "Epoch 179/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9757 - val_loss: 0.2863 - val_accuracy: 0.9298\n",
      "Epoch 180/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9757 - val_loss: 0.2890 - val_accuracy: 0.9325\n",
      "Epoch 181/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9774 - val_loss: 0.2766 - val_accuracy: 0.9281\n",
      "Epoch 182/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9750 - val_loss: 0.2784 - val_accuracy: 0.9333\n",
      "Epoch 183/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9772 - val_loss: 0.2802 - val_accuracy: 0.9351\n",
      "Epoch 184/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9779 - val_loss: 0.2882 - val_accuracy: 0.9316\n",
      "Epoch 185/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9781 - val_loss: 0.2744 - val_accuracy: 0.9342\n",
      "Epoch 186/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9792 - val_loss: 0.3066 - val_accuracy: 0.9333\n",
      "Epoch 187/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9770 - val_loss: 0.2833 - val_accuracy: 0.9351\n",
      "Epoch 188/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9779 - val_loss: 0.2909 - val_accuracy: 0.9360\n",
      "Epoch 189/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9781 - val_loss: 0.2714 - val_accuracy: 0.9386\n",
      "Epoch 190/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9774 - val_loss: 0.2836 - val_accuracy: 0.9386\n",
      "Epoch 191/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9796 - val_loss: 0.2766 - val_accuracy: 0.9333\n",
      "Epoch 192/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9794 - val_loss: 0.2903 - val_accuracy: 0.9316\n",
      "Epoch 193/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9789 - val_loss: 0.2846 - val_accuracy: 0.9342\n",
      "Epoch 194/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9781 - val_loss: 0.2913 - val_accuracy: 0.9342\n",
      "Epoch 195/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9792 - val_loss: 0.3017 - val_accuracy: 0.9325\n",
      "Epoch 196/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.2772 - val_accuracy: 0.9377\n",
      "Epoch 197/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9776 - val_loss: 0.2812 - val_accuracy: 0.9333\n",
      "Epoch 198/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9794 - val_loss: 0.2905 - val_accuracy: 0.9360\n",
      "Epoch 199/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9781 - val_loss: 0.3006 - val_accuracy: 0.9351\n",
      "Epoch 200/200\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9803 - val_loss: 0.2835 - val_accuracy: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf8355ad60>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.fit(x_train,y_train,batch_size=100,epochs=200,validation_data=(x_test,y_test),shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622ea2b",
   "metadata": {},
   "source": [
    "## convertiing probabilities to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c6713a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann_model.predict(x_test)\n",
    "for i in range(0,len(y_pred)):\n",
    "    if y_pred[i]>=.5:\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "822125f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict[\"model\"].append('ANN')\n",
    "my_dict[\"accuracy\"].append(round(accuracy_score(y_test,y_pred)*100,2))\n",
    "my_dict[\"precision\"].append(round(precision_score(y_test,y_pred)*100,2))\n",
    "my_dict[\"recall\"].append(round(recall_score(y_test,y_pred)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc54fde6",
   "metadata": {},
   "source": [
    "## Final performance matrix of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "044041ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>76.75</td>\n",
       "      <td>75.63</td>\n",
       "      <td>78.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>98.42</td>\n",
       "      <td>97.10</td>\n",
       "      <td>99.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>99.91</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>94.12</td>\n",
       "      <td>99.80</td>\n",
       "      <td>88.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>89.30</td>\n",
       "      <td>89.44</td>\n",
       "      <td>89.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANN</td>\n",
       "      <td>93.60</td>\n",
       "      <td>90.54</td>\n",
       "      <td>97.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  accuracy  precision  recall\n",
       "0          LogisticRegression()     76.75      75.63   78.95\n",
       "1      DecisionTreeClassifier()     98.42      97.10   99.82\n",
       "2      RandomForestClassifier()     99.91     100.00   99.82\n",
       "3  GradientBoostingClassifier()     94.12      99.80   88.42\n",
       "4                         SVC()     89.30      89.44   89.12\n",
       "5                           ANN     93.60      90.54   97.37"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(my_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
